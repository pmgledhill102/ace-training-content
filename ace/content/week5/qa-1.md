---

**Question 1:** A security team needs to track all administrative changes, such as modifying IAM roles and VM configurations, within a Google Cloud project. They also want to log all API calls that read or write data in their Cloud Storage buckets. The team wants to ensure the administrative change logs are kept for over a year at no cost.

Which combination of audit logs and configurations should they use?

- A. Enable Data Access audit logs and rely on the default retention for Admin Activity audit logs.
- B. Enable System Event audit logs and Data Access audit logs, and configure a 400-day retention for all.
- C. Rely on the default Admin Activity logs and enable Policy Denied audit logs with custom retention.
- D. Enable Admin Activity audit logs and configure a log sink to export them to Cloud Storage.

---

**Question 1:** A security team needs to track all administrative changes, such as modifying IAM roles and VM configurations, within a Google Cloud project. They also want to log all API calls that read or write data in their Cloud Storage buckets. The team wants to ensure the administrative change logs are kept for over a year at no cost.

Which combination of audit logs and configurations should they use?

- **Correct: A. Enable Data Access audit logs and rely on the default retention for Admin Activity audit logs.** Admin Activity logs are always on, record administrative changes that modify the configuration or metadata of resources, are retained for 400 days by default, and are free of charge. Data Access audit logs must be enabled to record the reading and writing of user-provided data, such as objects in Cloud Storage, and are disabled by default (except for BigQuery).
- **Incorrect: B. Enable System Event audit logs and Data Access audit logs, and configure a 400-day retention for all.** System Event logs record actions by Google Cloud systems, not user-driven administrative changes. Also, the retention for Admin Activity logs is already 400 days by default and is non-configurable.
- **Incorrect: C. Rely on the default Admin Activity logs and enable Policy Denied audit logs with custom retention.** Policy Denied logs record when access is denied, not successful data access operations. They are also generated by default and you cannot disable them.
- **Incorrect: D. Enable Admin Activity audit logs and configure a log sink to export them to Cloud Storage.** Admin Activity logs are already enabled by default. While exporting is an option for longer retention, the default 400-day retention period already meets the "over a year" requirement at no cost.

---

**Question 2:** Your company uses a dedicated Google Cloud project for centralized logging. You need to route all logs from 50 different production projects to a single log bucket in this central logging project. You want to ensure this configuration is easy to manage and scales automatically as new production projects are added to your organization's "Production" folder.

What is the most effective method to achieve this?

- A. In each of the 50 production projects, create a log sink that exports to the central log bucket.
- B. In the central logging project, add all 50 production projects to its metrics scope.
- C. Create a folder-level aggregated sink on the "Production" folder that exports to the central log bucket.
- D. Use the gcloud CLI to write a script that periodically copies logs from each project.

---

**Question 2:** Your company uses a dedicated Google Cloud project for centralized logging. You need to route all logs from 50 different production projects to a single log bucket in this central logging project. You want to ensure this configuration is easy to manage and scales automatically as new production projects are added to your organization's "Production" folder. What is the most effective method to achieve this?

- **Incorrect: A. In each of the 50 production projects, create a log sink that exports to the central log bucket.** This approach is not scalable or easy to manage. It would require individual configuration for every project and doesn't scale well for new projects.
- **Incorrect: B. In the central logging project, add all 50 production projects to its metrics scope.** Metrics scopes are a Cloud Monitoring feature for viewing metrics from multiple projects together. They do not affect log routing.
- **Correct: C. Create a folder-level aggregated sink on the "Production" folder that exports to the central log bucket.** Aggregated sinks can be configured at the folder or organization level to automatically collect and route logs from all child resources (including new ones) to a single destination, making it the most efficient and scalable solution.
- **Incorrect: D. Use the gcloud CLI to write a script that periodically copies logs from each project.** This is a complex, non-native workaround. Log sinks are the intended and reliable feature for routing logs in real time.

---

**Question 3:** An application running on Compute Engine is generating a high volume of debug logs that are not needed for production monitoring but are filling up your log storage and incurring costs. You want to prevent these specific debug logs from being ingested and stored in Cloud Logging, while still retaining all other logs (info, error, etc.).

What should you configure?

- A. A log-based metric to count the debug logs.
- B. A log exclusion filter in the Log Router.
- C. A log sink to route the debug logs to Pub/Sub.
- D. A custom retention rule on the `_Default` log bucket.

---

**Question 3:** An application running on Compute Engine is generating a high volume of debug logs that are not needed for production monitoring but are filling up your log storage and incurring costs. You want to prevent these specific debug logs from being ingested and stored in Cloud Logging, while still retaining all other logs (info, error, etc.).

What should you configure?

- **Incorrect: A. A log-based metric to count the debug logs.** Creating a metric will count the logs but will not stop them from being ingested or stored.
- **Correct: B. A log exclusion filter in the Log Router.** The Log Router uses exclusion filters to determine which log entries are discarded and not ingested into Cloud Logging. This is the correct way to prevent unwanted logs from being stored and incurring costs. Excluded entries will be gone forever.
- **Incorrect: C. A log sink to route the debug logs to Pub/Sub.** A log sink routes a copy of the logs to a destination but does not prevent them from also being stored in the default Cloud Logging buckets unless you also create an exclusion.
- **Incorrect: D. A custom retention rule on the `_Default` log bucket.** A retention rule changes how long logs are stored, but it does not prevent them from being ingested and charged for in the first place.

---

**Question 4:** You are tasked with monitoring the health of a public-facing e-commerce website. You need to be alerted if the website's homepage becomes inaccessible from different geographic locations. The check should validate that the HTTP response code is 200 (OK).

Which Cloud Monitoring feature is best suited for this requirement?

- A. A custom dashboard showing the server's CPU utilization.
- B. Cloud Trace to analyze the application's latency profile.
- C. A log-based alerting policy that looks for HTTP 200 status codes in the logs.
- D. An HTTP uptime check with an associated alerting policy.

---

**Question 4:** You are tasked with monitoring the health of a public-facing e-commerce website. You need to be alerted if the website's homepage becomes inaccessible from different geographic locations. The check should validate that the HTTP response code is 200 (OK).

Which Cloud Monitoring feature is best suited for this requirement?

- **Incorrect: A. A custom dashboard showing the server's CPU utilization.** Monitoring CPU utilization is important for server health but does not directly confirm if the website is accessible to external users.
- **Incorrect: B. Cloud Trace to analyze the application's latency profile.** Cloud Trace is for analyzing the performance and latency of internal application requests, not for checking external availability.
- **Incorrect: C. A log-based alerting policy that looks for HTTP 200 status codes in the logs.** This would be an indirect way of monitoring. It relies on logs being generated, and an absence of 200s doesn't necessarily mean the site is down. Uptime checks are the direct method.
- **Correct: D. An HTTP uptime check with an associated alerting policy.** Uptime checks are specifically designed to test the availability of public services from multiple locations around the world. You can configure an HTTP check to verify the response code and create an alerting policy to be notified of failures.

---

**Question 5:** Your organization has a policy of centralizing monitoring for related applications. You have a "big-app" application that spans four projects: `svc1`, `svc2`, `svc3`, and `svc4`. You need to create a single dashboard that displays CPU metrics from VMs in all four projects.

How should you configure Cloud Monitoring?

- A. Create an organization-level log sink to aggregate metrics from all projects.
- B. For each of the four projects, grant the Operations team the `monitoring.viewer` IAM role.
- C. Create a dedicated monitoring project and add the four service projects to its metrics scope.
- D. In each service project, create a custom dashboard and link them together.

---

**Question 5:** Your organization has a policy of centralizing monitoring for related applications. You have a "big-app" application that spans four projects: `svc1`, `svc2`, `svc3`, and `svc4`. You need to create a single dashboard that displays CPU metrics from VMs in all four projects.

How should you configure Cloud Monitoring?

- **Incorrect: A. Create an organization-level log sink to aggregate metrics from all projects.** Log sinks are for routing logs, not metrics.
- **Incorrect: B. For each of the four projects, grant the Operations team the `monitoring.viewer` IAM role.** This would grant access, but the team would still have to switch between the separate metrics scopes of each project and could not create a single, consolidated dashboard.
- **Correct: C. Create a dedicated monitoring project and add the four service projects to its metrics scope.** This is the recommended approach for production deployments to create a "single pane of glass" that provides visibility into a group of related projects. This allows for the creation of a single dashboard showing resources from all projects in the scope.
- **Incorrect: D. In each service project, create a custom dashboard and link them together.** Cloud Monitoring does not provide a feature to link separate dashboards together into a single view.

---

**Question 6:** An application is experiencing intermittent errors. You need to investigate the issue by reviewing logs in Cloud Logging. You want to find all log entries from a specific GKE container named `frontend-app` that have a severity level of `ERROR` or `CRITICAL` and occurred within the last 6 hours.

What is the most efficient way to do this in the Logs Explorer?

- A. Manually scroll through all logs from the last 6 hours and read each one to find the errors.
- B. Write a complex regular expression in the main search box to match the container name and severity.
- C. Use the query builder drop-down menus to select the GKE container resource, the `ERROR` and `CRITICAL` severity levels, and set the time range to the last 6 hours.
- D. Export all logs to BigQuery and then run a SQL query to filter the results.

---

**Question 6:** An application is experiencing intermittent errors. You need to investigate the issue by reviewing logs in Cloud Logging. You want to find all log entries from a specific GKE container named `frontend-app` that have a severity level of `ERROR` or `CRITICAL` and occurred within the last 6 hours.

What is the most efficient way to do this in the Logs Explorer?

- **Incorrect: A. Manually scroll through all logs from the last 6 hours and read each one to find the errors.** This is highly inefficient and impractical, especially with a large volume of logs.
- **Incorrect: B. Write a complex regular expression in the main search box to match the container name and severity.** While possible, using the dedicated filter builders is much easier and less error-prone for standard fields like resource and severity.
- **Correct: C. Use the query builder drop-down menus to select the GKE container resource, the `ERROR` and `CRITICAL` severity levels, and set the time range to the last 6 hours.** The Logs Explorer interface is designed for this exact purpose. The query builder drop-down menus and Log fields pane allow you to efficiently narrow down entries by resource, severity, and time range without writing complex queries manually.
- **Incorrect: D. Export all logs to BigQuery and then run a SQL query to filter the results.** This is a powerful option for complex, long-term analysis but is not the most efficient method for immediate, interactive troubleshooting, which is the primary use case for Logs Explorer.

---

**Question 7:** Your application is writing latency values in milliseconds to its log files. You want to create a chart in Cloud Monitoring that shows the statistical distribution (e.g., 50th, 95th, and 99th percentiles) of these latency values over time.

What type of log-based metric should you create?

- A. Counter
- B. Boolean
- C. Distribution
- D. Gauge

---

**Question 7:** Your application is writing latency values in milliseconds to its log files. You want to create a chart in Cloud Monitoring that shows the statistical distribution (e.g., 50th, 95th, and 99th percentiles) of these latency values over time.

What type of log-based metric should you create?

- **Incorrect: A. Counter** Counter metrics count the number of log entries that match a filter, they do not extract and analyze numeric values.
- **Incorrect: B. Boolean** Boolean metrics record whether a log entry matches a specified filter, representing it as a 0 or 1, but do not handle numeric distributions.
- **Correct: C. Distribution** Distribution metrics are specifically designed to extract numeric values from log entries and record their statistical distribution in histogram buckets, which allows for observing trends in data like latency.
- **Incorrect: D. Gauge** Gauge is a type of metric kind (it measures a value at a specific time), not a type of log-based metric. The log-based metric types are counter, distribution, and boolean.

---

**Question 8:** You are the lead SRE for a multi-tiered application. You need to create a centralized view that shows the most critical health signals for your entire service. This view must include the current request latency, the error rate as a ratio, the status of key uptime checks, and a list of recent critical alerts.

What is the best way to create this centralized view in Cloud Monitoring?

- A. Use the Metrics Explorer for each signal and share the URLs with your team.
- B. Create a custom dashboard and add widgets for charts, scorecards, alert policies, and uptime checks.
- C. Rely on the predefined dashboards that Google Cloud creates automatically for each service.
- D. Create a log-based metric for each signal and view them in the Logs Explorer.

---

**Question 8:** You are the lead SRE for a multi-tiered application. You need to create a centralized view that shows the most critical health signals for your entire service. This view must include the current request latency, the error rate as a ratio, the status of key uptime checks, and a list of recent critical alerts.

What is the best way to create this centralized view in Cloud Monitoring?

- **Incorrect: A. Use the Metrics Explorer for each signal and share the URLs with your team.** Metrics Explorer is for ad-hoc analysis and building individual charts. It does not provide a consolidated, persistent view of multiple different signals.
- **Correct: B. Create a custom dashboard and add widgets for charts, scorecards, alert policies, and uptime checks.** Custom dashboards are the primary tool for creating a persistent, consolidated view of metrics and other monitoring data that is important to you. The dashboard builder allows you to add a variety of widgets, including line charts and scorecards for metrics, as well as specific widgets to display the status of alerts and uptime checks.
- **Incorrect: C. Rely on the predefined dashboards that Google Cloud creates automatically for each service.** Predefined dashboards provide useful information for specific resource types (e.g., a GCE VM), but they won't provide a customized, holistic view that combines different metrics (like a ratio-based error rate) and signals (alerts, uptime checks) from across your entire application.
- **Incorrect: D. Create a log-based metric for each signal and view them in the Logs Explorer.** Logs Explorer is for viewing logs, not for creating a graphical dashboard of metrics, alerts, and uptime statuses.

---

**Question 9:** Your team has defined a Service Level Objective (SLO) for your application's availability as 99.9% over a rolling 30-day period. This leaves a 0.1% error budget. You need to configure an alert that notifies the team when the service is consuming its error budget too quickly, indicating a potential SLO breach.

Which type of alerting condition is specifically designed for this purpose in Service Monitoring?

- A. A metric threshold alert on the number of HTTP 5xx errors.
- B. A forecast condition predicting future error counts.
- C. An SLO burn rate alert.
- D. A metric absence alert monitoring the request count.

---

**Question 9:** Your team has defined a Service Level Objective (SLO) for your application's availability as 99.9% over a rolling 30-day period. This leaves a 0.1% error budget. You need to configure an alert that notifies the team when the service is consuming its error budget too quickly, indicating a potential SLO breach.

Which type of alerting condition is specifically designed for this purpose in Service Monitoring?

- **Incorrect: A. A metric threshold alert on the number of HTTP 5xx errors.** While related to availability, this alert is based on a raw metric. A burn rate alert is a more sophisticated condition directly tied to the SLO and its error budget consumption rate.
- **Incorrect: B. A forecast condition predicting future error counts.** Forecasting can predict when a threshold will be violated, but the SLO burn rate condition is specifically tailored to the consumption speed of an error budget.
- **Correct: C. An SLO burn rate alert.** Service Monitoring can trigger an alert when a service is projected to violate an SLO. The alerting policy uses a lookback window and a burn rate threshold to determine if the error budget is being consumed too quickly. This is the correct way to get early warning of a potential SLO breach.
- **Incorrect: D. A metric absence alert monitoring the request count.** A metric absence alert triggers when no data is reported for a period, which might indicate a total outage but doesn't track the rate of errors against an SLO.

---

**Question 10:** Your company's incident response policy requires that critical alerts for your production environment send a message to a specific Slack channel, send an SMS to the on-call engineer, and create a ticket in PagerDuty.

How can you configure this in Cloud Monitoring?

- A. Create three separate alerting policies, one for each notification type.
- B. Configure a single alerting policy with three different notification channels: Slack, SMS, and PagerDuty.
- C. Configure a Pub/Sub notification channel and write a Cloud Function to integrate with Slack, SMS, and PagerDuty.
- D. Use the gcloud command-line tool to send alerts directly to the required services.

---

**Question 10:** Your company's incident response policy requires that critical alerts for your production environment send a message to a specific Slack channel, send an SMS to the on-call engineer, and create a ticket in PagerDuty.

How can you configure this in Cloud Monitoring?

- **Incorrect: A. Create three separate alerting policies, one for each notification type.** This is inefficient. A single incident should be managed by a single policy.
- **Correct: B. Configure a single alerting policy with three different notification channels: Slack, SMS, and PagerDuty.** An alerting policy can have multiple notification channels of different types. Cloud Monitoring provides native support for these channels, allowing you to select all of them for a single policy.
- **Incorrect: C. Configure a Pub/Sub notification channel and write a Cloud Function to integrate with Slack, SMS, and PagerDuty.** While technically possible, this is overly complex as Cloud Monitoring provides direct integrations for these services. This approach adds unnecessary development and maintenance overhead.
- **Incorrect: D. Use the gcloud command-line tool to send alerts directly to the required services.** The `gcloud` tool is used for managing policies and channels, not for sending the alert notifications themselves. The Monitoring service sends the notifications when a policy is triggered.

---

**Question 11:** You need to monitor a fleet of Compute Engine VMs and collect detailed process-level metrics, host metrics, and metrics from third-party applications like Nginx and MySQL running on the VMs.

What is the recommended Google Cloud tool to install on your VMs to collect this telemetry?

- A. The `gcloud` command-line interface.
- B. The Ops Agent.
- C. A custom script that writes to the Cloud Logging API.
- D. The Prometheus node exporter.

---

**Question 11:** You need to monitor a fleet of Compute Engine VMs and collect detailed process-level metrics, host metrics, and metrics from third-party applications like Nginx and MySQL running on the VMs.

What is the recommended Google Cloud tool to install on your VMs to collect this telemetry?

- **Incorrect: A. The `gcloud` command-line interface.** The `gcloud` CLI is for managing Google Cloud resources, not for collecting telemetry from within a VM.
- **Correct: B. The Ops Agent.** For applications on Compute Engine, the Ops Agent is the recommended tool to collect in-process metrics, host metrics, and metrics from supported third-party applications.
- **Incorrect: C. A custom script that writes to the Cloud Logging API.** This would require significant development effort and would not provide the rich, out-of-the-box integrations that the Ops Agent provides.
- **Incorrect: D. The Prometheus node exporter.** While the node exporter provides host metrics, the Ops Agent provides a more integrated solution for both logs and metrics, including third-party application support and process metrics, all within the Google Cloud ecosystem.

---

**Question 12:** Which statement accurately describes the relationship between Service Level Indicators (SLIs), Service Level Objectives (SLOs), and Service Level Agreements (SLAs)?

- A. An SLA is a target for an SLI, and an SLO is the business contract with the customer.
- B. An SLI is a quantifiable measure of reliability, an SLO is a target for that SLI, and an SLA is a formal contract with customers that may have consequences for not meeting an SLO.
- C. An SLO is a measurement of latency or errors, an SLI is the goal for that measurement, and an SLA is an internal team agreement.
- D. An SLI, SLO, and SLA are all internal metrics used by the SRE team and have no customer-facing implications.

---

**Question 12:** Which statement accurately describes the relationship between Service Level Indicators (SLIs), Service Level Objectives (SLOs), and Service Level Agreements (SLAs)?

- **Incorrect: A. An SLA is a target for an SLI, and an SLO is the business contract with the customer.** This reverses the definitions of SLO and SLA.
- **Correct: B. An SLI is a quantifiable measure of reliability, an SLO is a target for that SLI, and an SLA is a formal contract with customers that may have consequences for not meeting an SLO.** This correctly defines the hierarchy. An SLI is a carefully selected metric that measures a service's reliability. An SLO combines that SLI with a target reliability level. An SLA is a commitment to customers about service levels and the consequences of failing to meet them.
- **Incorrect: C. An SLO is a measurement of latency or errors, an SLI is the goal for that measurement, and an SLA is an internal team agreement.** This reverses the definitions of SLI and SLO.
- **Incorrect: D. An SLI, SLO, and SLA are all internal metrics used by the SRE team and have no customer-facing implications.** SLAs are explicitly customer-facing agreements with potential financial consequences.

---

**Question 13:** A developer is troubleshooting a slow-performing, distributed application. They need to understand the complete path of a user request as it travels through multiple microservices to identify which service is causing the bottleneck.

Which Google Cloud Observability tool is specifically designed for this purpose?

- A. Cloud Profiler
- B. Error Reporting
- C. Cloud Trace
- D. Logs Explorer

---

**Question 13:** A developer is troubleshooting a slow-performing, distributed application. They need to understand the complete path of a user request as it travels through multiple microservices to identify which service is causing the bottleneck.

Which Google Cloud Observability tool is specifically designed for this purpose?

- **Incorrect: A. Cloud Profiler** Cloud Profiler analyzes CPU and heap consumption within a single service to find inefficient code, but it does not trace requests across multiple services.
- **Incorrect: B. Error Reporting** Error Reporting aggregates and analyzes application crashes and exceptions; it does not track latency for successful requests.
- **Correct: C. Cloud Trace** Cloud Trace is a distributed tracing system that collects latency data from distributed applications and displays it in the console. It is designed to help understand the path and latency of requests as they travel through different services.
- **Incorrect: D. Logs Explorer** While logs can contain timing information, they do not provide the structured, hierarchical view of a request's journey across services that Cloud Trace does.

---

**Question 14:** Your team wants to automate the creation and management of Cloud Monitoring alerting policies using Infrastructure as Code (IaC). They have chosen Terraform as their tool.

What is the first step in creating an alerting policy using Terraform?

- A. Write a Cloud Function that uses the Monitoring API.
- B. Define a `google_monitoring_alert_policy` resource in a `.tf` configuration file.
- C. Manually create the policy in the Cloud Console and export its JSON representation.
- D. Use the `gcloud monitoring policies create` command.

---

**Question 14:** Your team wants to automate the creation and management of Cloud Monitoring alerting policies using Infrastructure as Code (IaC). They have chosen Terraform as their tool.

What is the first step in creating an alerting policy using Terraform?

- **Incorrect: A. Write a Cloud Function that uses the Monitoring API.** This is a custom code solution, not using IaC with Terraform.
- **Correct: B. Define a `google_monitoring_alert_policy` resource in a `.tf` configuration file.** To create resources with Terraform, you must declare them in configuration files. The `google_monitoring_alert_policy` resource is the correct declaration for creating an alerting policy.
- **Incorrect: C. Manually create the policy in the Cloud Console and export its JSON representation.** While exporting can help you understand the structure, the primary step for IaC is to write the declarative configuration file yourself.
- **Incorrect: D. Use the `gcloud monitoring policies create` command.** This is using the command-line interface, not Terraform, to manage the resource.

---

**Question 15:** A new developer on your team is trying to understand the Logs Explorer interface. They want to filter logs to show only those coming from a specific Compute Engine instance.

Which pane in the Logs Explorer interface should they use to most easily filter by resource type and then select the specific instance?

- A. Query pane
- B. Results toolbar
- C. Histogram
- D. Log fields pane

---

**Question 15:** A new developer on your team is trying to understand the Logs Explorer interface. They want to filter logs to show only those coming from a specific Compute Engine instance.

Which pane in the Logs Explorer interface should they use to most easily filter by resource type and then select the specific instance?

- **Incorrect: A. Query pane** The query pane is where the query is built and displayed, but the filtering action itself is often initiated from other panes.
- **Incorrect: B. Results toolbar** The results toolbar has functions like creating metrics or jumping to the current time; it is not used for building the query filter.
- **Incorrect: C. Histogram** The histogram visualizes the distribution of logs over time and can be used to narrow the time range, but not to filter by resource instance.
- **Correct: D. Log fields pane** The Log fields pane provides a high-level summary and allows for efficient query refinement by showing log entries sorted by fields like resource type. A user can click on the resource type and then the specific instance ID to add it to the query filter.
```
